{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35207790-d46e-49cb-af13-2ccc21ce83d5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Access respective Azure storage container and blob to fetch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8024376f-01b0-4741-b07b-24c3d8f5209d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Azure storage access info\n",
    "blob_account_name = \"azureopendatastorage\"\n",
    "blob_container_name = \"holidaydatacontainer\"\n",
    "blob_relative_path = \"Processed\"\n",
    "blob_sas_token = r\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce3fa763-547d-487d-a29b-f32a3fd0c078",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Construct remote blob path to access the parquet files remotely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1afb50a-ab19-4a01-8712-dd334012d5a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Allow SPARK to read from Blob remotely\n",
    "wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
    "spark.conf.set(\n",
    "  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
    "  blob_sas_token)\n",
    "print('Remote blob path: ' + wasbs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01d17c92-f518-422a-9016-63b676560f10",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Read the parquet files and load the data into Temporary view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48fdf5c4-2dbe-4480-b499-9e9880c9bd8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SPARK read parquet, note that it won't load any data yet by now\n",
    "df = spark.read.parquet(wasbs_path)\n",
    "print('Register the DataFrame as a SQL temporary view: PublicHoliday')\n",
    "df.createOrReplaceTempView('PublicHoliday')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28fa2def-727e-4d6f-944c-4f5b2ce32d4d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### SQL Operations on the Temporary View."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5359945f-820b-48c3-a4f5-d1bc90b60193",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Display total number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50f48e9a-ccf2-44fd-bdac-51267b7d0d3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sqlQuery = 'SELECT COUNT(*) as Count FROM PublicHoliday'\n",
    "display(spark.sql(sqlQuery))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed8d973d-5a97-4d70-a914-bfb48136a65a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Display top 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5c5ea54-d0dc-406c-9499-99ff13dde47b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display top 10 rows\n",
    "print('Displaying top 10 rows: ')\n",
    "sqlQuery = 'SELECT * FROM PublicHoliday LIMIT 10'\n",
    "display(spark.sql(sqlQuery))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29006a97-4355-4f99-9adb-6cea27418292",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Display records by specifying column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8202c2f7-8d2f-4083-9dd1-da81cdfce506",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sqlQuery = 'SELECT countryOrRegion,countryRegionCode,holidayName,normalizeHolidayName,date,isPaidTimeOff FROM PublicHoliday'\n",
    "display(spark.sql(sqlQuery))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b6d3163-a61f-4af5-92a1-36e8b9ec359b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Display the list of unique Country and region code from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "400dc0f2-3695-4ec3-93a4-222653cab0ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sqlQuery = 'SELECT distinct countryRegionCode, countryOrRegion FROM PublicHoliday order by countryRegionCode asc '\n",
    "display(spark.sql(sqlQuery))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d95b7fbf-fe6d-4749-b36f-d467af02f3e7",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Display the list of unique PaidTimeOff from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48b9c259-31b5-4098-94f2-c0d8b89455ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sqlQuery = 'SELECT distinct isPaidTimeOff FROM PublicHoliday'\n",
    "display(spark.sql(sqlQuery))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9714980c-cc19-4231-867e-727cd2e068b6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Display the list of Country, Holiday count by year from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ee5cb0e-9cf5-4e4a-8de3-70d7c7812af3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sqlQuery = 'SELECT countryOrRegion AS Country, YEAR(date) as Year, COUNT(HolidayName) AS HolidayCount FROM PublicHoliday GROUP BY countryOrRegion, YEAR order by countryOrRegion, Year'\n",
    "display(spark.sql(sqlQuery))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d18fe07-ee39-4903-9d2e-286efbfa94f5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Display the list of Country, Holiday count by year from the data for the year 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5331b98a-fb6f-4ce3-9333-2af400d243c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sqlQuery = 'SELECT countryOrRegion AS Country, YEAR(date) as Year, COUNT(HolidayName) AS HolidayCount FROM PublicHoliday WHERE YEAR(date) = 2025 GROUP BY countryOrRegion, YEAR order by countryOrRegion, Year'\n",
    "display(spark.sql(sqlQuery))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94be2eee-b088-44ea-aa2f-1e9bfb2f184c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Display the list of Country, Holiday count by year from the data for the year 2025 and filter by PaidTimeOff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aabc2880-051e-4dbe-bcc0-42e9de532077",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql('SELECT countryOrRegion AS Country, YEAR(date) as Year, COUNT(HolidayName) AS HolidayCount FROM PublicHoliday WHERE YEAR(date) = 2025 AND isPaidTimeOff = true GROUP BY countryOrRegion, YEAR order by countryOrRegion, Year'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c49d6ef3-2a11-47f4-9bd9-fd02d117c91b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Display the list of Country, Holiday Name, Date and PaidTime off from the data for the year 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25cbf621-5674-4b26-8031-826c96fbfca0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sqlQuery = \"SELECT countryOrRegion AS Country,countryRegionCode AS CountryCode,holidayName AS HolidayName,CAST(date AS DATE) AS HolidayDate,isPaidTimeOff FROM PublicHoliday WHERE YEAR(date) = 2025 AND countryOrRegion = 'India'\"\n",
    "display(spark.sql(sqlQuery))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98c6f9f0-2d7c-4bb7-b367-bcddd7b8c9aa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Display the list of Country, Holiday Name, Date and PaidTime off from the data for the year 2025 and filter by PaidTimeOff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07a06230-2df7-44a6-b0f0-46691bc2b177",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sqlQuery = \"SELECT countryOrRegion AS Country,countryRegionCode AS CountryCode,holidayName AS HolidayName,CAST(date AS DATE) AS HolidayDate,isPaidTimeOff FROM PublicHoliday WHERE YEAR(date) = 2025 AND countryOrRegion = 'India' and isPaidTimeOff = true\"\n",
    "display(spark.sql(sqlQuery))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ed20131-dbc6-4148-8aca-117c5ea8b1f6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Display the list of Country, Holiday Name, Date and Day of the week from the data for the year 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e83f5a0-f249-4732-b902-681dcea97c17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sqlQuery = \"SELECT countryOrRegion AS Country,holidayName AS HolidayName,CAST(date AS DATE) AS HolidayDate,date_format((CAST(date AS DATE)),'EEEE') AS DayOfWeek FROM PublicHoliday WHERE YEAR(date) = 2025 AND countryOrRegion = 'India'\"\n",
    "display(spark.sql(sqlQuery))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Public Holidays",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
